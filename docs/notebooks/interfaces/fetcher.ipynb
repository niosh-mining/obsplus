{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetcher\n",
    " \n",
    "The Fetcher class builds on the unified data request interfaces to provide convenient methods for working with whole datasets. Specifically, you can:\n",
    " \n",
    "1. Get continuous data using channels contained in an inventory (or returned from a station_client).\n",
    "\n",
    "\n",
    "2. Iterate over events and their corresponding waveforms, which have channels defined by the station_client. \n",
    "\n",
    "Additionally, more methods are certainly possible and may be implemented in the future.\n",
    "\n",
    "## Setup\n",
    "We will use a Fetcher from the TA and Crandall dataset to demonstrate different aspects of the `Fetcher` functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obsplus\n",
    "\n",
    "ta_dataset = obsplus.load_dataset('ta')\n",
    "crandall = obsplus.load_dataset('crandall')\n",
    "\n",
    "ta_fetcher = ta_dataset.get_fetcher()\n",
    "crandall_fetcher = crandall.get_fetcher()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, the Fetcher can be initialized with any objects from which the appropriate client can be obtained. Commonly it is used with a `WaveBank`, a `Catalog` (or `EventBank`) and an `Inventory`. The following would also be valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = crandall.event_client.get_events()\n",
    "inv = crandall.station_client.get_stations()\n",
    "wavebank = crandall.waveform_client\n",
    "\n",
    "crandall_fetcher = obsplus.Fetcher(waveforms=wavebank, stations=inv, events=cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The WaveFetcher constructor can also take obsplus created csv/dataframes for the [stations](../datastructures/stations_to_pandas.ipynb) and [events](../datastructures/events_to_pandas.ipynb) arguments. However, this may limit some of the uses of the Fetcher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick fetch\n",
    "The easiest way to get data out of a data fetcher is to call it. The fetcher takes an argument that will provide it with information about when the stream should start. It can be a variety of types (float, UTCDateTime, Catalog, Event). The time before the reference time, and the time after the reference time must also be provided in the method call or in the Fetcher construction. \n",
    "\n",
    "The fetcher uses the inventory (or `station_client`) to know which channels to request from the waveform_client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "reference_time = obspy.UTCDateTime('2007-02-15T06')\n",
    "time_before = 1\n",
    "time_after = 30\n",
    "stream = ta_fetcher(reference_time, time_before, time_after)\n",
    "print(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous data\n",
    "\n",
    "Continuous data can be requested from the wavefetcher, which uses the `station_client` to know which channels to pull from the waveform_client. This enables users to skip a lot of the boiler-plate associated with the normal `get_waveforms` interface.  \n",
    "\n",
    "For example, looping over all the continuous data and and running a simple STA/LTA detector could be done like so: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.signal.trigger import classic_sta_lta\n",
    "\n",
    "# first define a function for doing the sta/lta\n",
    "def print_sta_lta(tr: obspy.Trace):\n",
    "    \"\"\" prints the sta/lta \"\"\"\n",
    "    sr = tr.stats.sampling_rate\n",
    "    cft = classic_sta_lta(tr.data, int(20 * sr), int(60 * sr))\n",
    "    print(f'{tr.id} starting at {st[0].stats.starttime}, has a max sta/lta of {max(cft):0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starttime for the continuous data\n",
    "t1 = obspy.UTCDateTime('2007-02-16')\n",
    "\n",
    "# endtime for the continuous data\n",
    "t2 = t1 + 36000 * 10  # use 10 hours\n",
    "\n",
    "# duration of each chunk returned (in seconds)\n",
    "duration = 72000\n",
    "\n",
    "# overlap (added to the end of the duration)\n",
    "overlap = 60\n",
    "\n",
    "# iterate over each chunk\n",
    "for st in ta_fetcher.yield_waveforms(t1, t2, duration, overlap):\n",
    "    # select only z component and perform preprocessing\n",
    "    st = st.select(component='Z')\n",
    "    st.detrend('linear')\n",
    "    # do the sta/lta\n",
    "    for tr in st:\n",
    "        print_sta_lta(tr)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream processors\n",
    "\n",
    "It can be useful to define a stream_processing function that will be called on each stream before yielding it. This allows users to define flexible, custom processing functions without cluttering up the function calls with a lot of processing parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that will be called on the stream before returning it. \n",
    "def stream_processor(st: obspy.Stream) -> obspy.Stream:\n",
    "    \"\"\" select the z component, detrend, and filter a stream \"\"\"\n",
    "    st = st.select(component='Z')\n",
    "    st.detrend('linear')\n",
    "    st.filter('bandpass', freqmin=.005, freqmax=.04)\n",
    "    return st\n",
    "\n",
    "# attach stream processor to the wave fetcher\n",
    "ta_fetcher.stream_processor = stream_processor\n",
    "\n",
    "for st in ta_fetcher.yield_waveforms(t1, t2, duration, overlap):\n",
    "    for tr in st:\n",
    "        print_sta_lta(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event data\n",
    "\n",
    "Because we provided the wavefetcher object with an event_client, we can use it to iterate through the events it contains. Of course this should only be done with reasonably sized event clients, or the events should be limited in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_before = 1\n",
    "time_after = 3\n",
    "iterrator = crandall_fetcher.yield_event_waveforms(time_before, time_after)\n",
    "for event_id, st in iterrator:\n",
    "    print(f'fetched waveform data for {event_id} which has {len(st)} traces')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a dict of {event_id: stream} which is common input for converting streams to a [DataArray](../datastructures/xarray.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_dict = dict(crandall_fetcher.yield_event_waveforms(time_before, time_after))\n",
    "\n",
    "for event_id, st in st_dict.items():\n",
    "    print(event_id, len(st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different events/inventories\n",
    "The clients can be swapped out on each method call. This may be be useful to get a subset of the events or channels by providing a filtered catalog/inventory. For example, if we were only interested in Station M11A for a single call (but didn't want to modify the original wavefetcher) this could be easily accomplished like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a subset of the original inventory ()\n",
    "inv = ta_dataset.station_client.get_stations()\n",
    "inv2 = inv.select(station='M11A')\n",
    "\n",
    "# iterate and print\n",
    "for st in ta_fetcher.yield_waveforms(t1, t2, duration, overlap, stations=inv2):\n",
    "    for tr in st:\n",
    "        print_sta_lta(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same applies for swapping out events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in catalog as and get a subset as a dataframe\n",
    "cat = crandall.event_client.get_events()\n",
    "cat_df = obsplus.events_to_df(cat)[:2]\n",
    "\n",
    "# iterate the events and print \n",
    "iterator = crandall_fetcher.yield_event_waveforms(time_before, time_after, events=cat_df)\n",
    "for event_id, st in iterator:\n",
    "    print(f'fetching {event_id}, got {len(st)} traces')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
