{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "ObsPlus includes a few interesting datasets which are primarily for testing purposes. The datasets are \"lazy\" in that all but the most essential information will be downloaded only when some code requests the dataset. This helps keep the size of ObsPlus small, but does mean you will need an internet connection the first time you use each dataset. Here are the dataset included in ObsPlus:\n",
    "\n",
    "\n",
    "## Included Datasets\n",
    "\n",
    "1. Kemmerer:\n",
    "    A few days of continuous data recorded by TA stations M17A and M18A back in 2009 near Kemmerer Wyoming (USA). The stations recorded several nearby mine blasts, and I used these stations in [my MS thesis](https://academic.oup.com/gji/article-abstract/203/2/1388/584019) (shameless plug). This data set provides continuous waveform data for two stations, a catalog of mining blasts, and an inventory. \n",
    "    \n",
    "2. TA:\n",
    "    A small dataset with two stations from the TA with channels that have very low sampling rates. \n",
    "\n",
    "3. Crandall:\n",
    "    Event waveforms for the [Crandall Canyon Mine collapse](https://en.wikipedia.org/wiki/Crandall_Canyon_Mine) and associated aftershocks. This dataset includes only event waveforms, but it has them for many TA and UUSS stations. It also includes a catalog of the events and a station inventory.\n",
    "    \n",
    "4. Bingham:\n",
    "    Event waveforms associated with the [Bingham Canyon Landslide](https://en.wikipedia.org/wiki/Bingham_Canyon_Mine#Landslides), one of the largest anthropogenic landslides ever recorded. Luckily, the situation was well managed and no one was hurt. \n",
    "    \n",
    "Each of these data sets is accessed via `obsplus.load_dataset` function which takes the name of the dataset as the only argument. It then returns a `DataSet` instance. This will take a few minutes if the datasets have not yet been downloaded, otherwise it should be very quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obsplus\n",
    "crandall = obsplus.load_dataset('crandall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you plan to modify and data, Datasets can be copied with the copy_dataset function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "obsplus.copy_dataset('crandall', '.')\n",
    "path = Path('.') / 'crandall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "assert path.exists() and path.is_dir()  # ensure the directory was created\n",
    "shutil.rmtree(path)  # cleanup created directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset paths\n",
    "By default, all datasets are stored in the user's home directory in a directory called 'opsdata'. Each dataset is contained by a subdirectory with the same name as the dataset. If you would prefer the datasets be stored somewhere else the locations can be controlled by the environmental variable `OPSDATA_PATH`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publishing your own datasets\n",
    "ObsPlus' `DataSet` class can be used to bundle and distribute any seismological dataset. This is primarily done through creating a small python package containing only essential (tiny) data files and instructions for downloading larger datafiles. The package can then be published to [PyPI](https://pypi.org/) and shared with the world! If that sounds hard, don't worry! We have made a [cookiecutter template](https://github.com/seismopy/opsdata) for just this purpose. It even includes files for testing and scripts to automate releases and data versioning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
